# How We Deployed The AMP PD Target Explorer Using Google Cloud Platform
A Use-Case in Modern Cloud-based Solution Delivery

## Introducing the AMP PD Target Explorer

At [Technome](https://www.technome.io), we bring together a unique blend of top-notch data management and harmonization, scientific expertise, and engineering experience to provide services and solutions for our clients. One of our recent deliveries is the [AMP PD Target Explorer](https://www.target-explorer.amp-pd.org). This application was developed for the Accelerating Medical Partnerships - Parkinson’s Disease (AMP PD) program at the Foundation for the National Institutes of Health (FNIH).

The AMP PD Target Explorer is a tool for public users, perhaps with less Data Science background to explore and validate gene lists in their own analyses against analyses conducted by other members of the Parkinson’s Disease research community.

## High Level Application Architecture

The system architecture is the classic three-tier architecture: client-server-database. The N-tier model is an architectural pattern for designing software applications that divides the application into multiple logical layers or tiers, each responsible for specific functionalities. The "N" in N-tier stands for the number of tiers or layers, and it can vary based on the specific needs and complexity of the application. The most common configurations are 3-tier and 4-tier architectures, but more complex applications can have additional tiers. Here is a high-level overview, with the Target Explorer website available on any device with a web browser.

![High Level Architecture Diagram](/images/TargetExplorerHLA.jpg)

Why did we use the 3-tier model, compared to a monolithic application? Monolithic applications provide efficiencies of communication and data modeling, but tend to be more brittle because of tight coupling between functions. They are also less reliable, as a single error tends to affect the entire application’s availability. The n-tier model provides a clean distinction between the user interface and the business logic functionality. Separating the front-end client from the API server also allows us to open up the API services to external integrations, for example, other systems that might want to combine the Target Explorer data with other datasets. The Target Explorer API provides an OpenAPI standard RESTful interface. A user-friendly web-page for interacting with the API services is auto-generated with the Swagger toolset. Using a separately hosted database server allows the application to be loosely coupled to the actual data source, as well as easily interoperable across cloud providers. 

Why not use a microservice architecture? The microservice model promises modularity, scalability, and fault tolerance. The simple answer is that building a microservice system from scratch is complicated and time-consuming. Industry experience has shown that successful implementations of microservices tended to start as a monolith that needed to be broken into smaller services. Building a new product at speed means the first implementation is rarely optimized, trading less-than-optimal performance for agility and quick improvement cycles. For the Target Explorer, we found that horizontal scalability, performance and reliability were most easily achieved through selecting and configuring appropriate cloud deployment services.

The Target Explorer is a polyglot system. The front-end application is written in Typescript using the Angular framework. The API server is written in Python using the FastAPI framework. Data models are defined and validated using the Pydantic library, which is the default schema validator for FastAPI. The NoSQL database is hosted on MongoDB Atlas on the Google Cloud Platform. Both the front-end and API are deployed to Google App Engine (GAE). From the official docs: “App Engine is a fully managed, serverless platform for developing and hosting web applications at scale. You can choose from several popular languages, libraries, and frameworks to develop your apps, and then let App Engine take care of provisioning servers and scaling your app instances based on demand.”

## CI/CD

We follow industry best practices for automated CI/CD. The codebase for the front-end and API are hosted on GitHub. We set up Triggers in Google Cloud Build to automatically build and deploy our services. From the docs: “Cloud Build is a service that executes your builds on Google Cloud. Cloud Build can import source code from a variety of repositories or cloud storage spaces, execute a build to your specifications, and produce artifacts such as Docker containers or Java archives. You can also use Cloud Build to help protect your software supply chain. Cloud Build features meet the requirements of Supply chain Levels for Software Artifacts (SLSA) level 3.” Using the Cloud Build and App Engine config files to define the build process and deployment environment, we  deploy to three different environments on App Engine for a phased approach to software testing and deployment : “development”, “test”, and “production”. The “dev” environment is rebuilt/redeployed on any commit to the “develop” branch. Any issues with building or deployment are caught immediately. The “test” and “prod” environments are triggered on a commit tag matching a regular expression, for example “test1.0.1”. Likewise, there are three database instances to support each environment. New datasets are manually curated and reviewed before being promoted to each database environment.

Passwords, secret keys, PII, or other sensitive information should never be committed to a source code repository. We use the Google Secret Manager to store credentials for access to the database server. The Secret Manager API allows fine grained control over access to secrets, in this case specifically to allow the Target Explorer API service to retrieve credentials for access to the MongoDB database service.

## Summary

We took full advantage of the powerful suite of tools provided by Google Cloud Platform to build and deploy the AMP PD Target Explorer. Of course, GCP is not the only cloud platform that provides cloud-native devops tools, but it does integrate well with the other data management and analytics platforms we use at Technome.
